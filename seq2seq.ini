[strings]
# Mode : train, test, serve
mode = test
train_enc = data/train.enc
train_dec = data/train.dec
test_enc = data/test.enc
test_dec = data/test.enc

# folder where checkpoints, vocabulary, temporary data will be stored
working_directory = working_dir/


[ints]

enc_vocab_size = 20000
dec_vocab_size = 20000

# number of LSTM layers : 1/2/3
num_layers = 3

# typical options : 128, 256, 512, 1024
layer_size = 128
max_train_data_size = 0
batch_size = 64
steps_per_checkpoint = 300


[floats]
learning_rate = 0.5
learning_rate_decay_factor = 0.99
max_gradient_norm = 5.0

